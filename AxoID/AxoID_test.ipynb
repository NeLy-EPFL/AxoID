{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AxoID tests\n",
    "Notebook used to test detection and tracking together to start the work for AxoID.  \n",
    "Workflow:\n",
    "   1. Detection:\n",
    "      1. Predict using deep network (generate detections)\n",
    "      2. Decide if results are good:\n",
    "         * Yes: continue to 2.\n",
    "         * No: continue to 1.C\n",
    "      3. Make manual annotations (to be done externally to this notebook)\n",
    "      4. Fine tune the deep network (i.e., retrain it with manual annotations)\n",
    "      5. Go to 1.B\n",
    "   2. User correction (optional) (to be done externally to this notebook)\n",
    "   3. Tracking:\n",
    "      1. Select an initialization frame\n",
    "      2. Track axons:\n",
    "         * Train model\n",
    "         * Generate final identities\n",
    "   4. User correction (optional) (to be done externally to this notebook)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import os, sys, time, shutil, copy, time\n",
    "import re\n",
    "import warnings\n",
    "import random\n",
    "import ipywidgets as widgets\n",
    "from ipywidgets import interact\n",
    "from IPython.display import clear_output\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "from skimage import io, external, measure, morphology, filters, feature, color, segmentation\n",
    "from scipy import ndimage as ndi\n",
    "from scipy import stats\n",
    "import cv2\n",
    "import imgaug.augmenters as iaa\n",
    "\n",
    "import torch\n",
    "\n",
    "from utils_common.image import imread_to_float, to_npint, overlay_preds_targets, overlay_mask\n",
    "from utils_common.metrics import dice_coef\n",
    "from utils_common.register_cc import register_stack, shift_image\n",
    "from utils_common.processing import nlm_denoising, fuse_small_objects\n",
    "# Following are copy-pasted from other folders. Check that they are up-to-date\n",
    "from utils_data import normalize_range, get_all_dataloaders, pad_transform, pad_transform_stack, compute_weights\n",
    "from utils_finetuning import fine_tune, ROIAnnotator_mpl\n",
    "from utils_loss import get_BCEWithLogits_loss\n",
    "from utils_metric import get_dice_metric\n",
    "from utils_model import CustomUNet, load_model\n",
    "from utils_test import predict, predict_stack, evaluate, evaluate_stack\n",
    "from internal_model import InternalModel\n",
    "from utils_tracking import get_rules, rules_violated\n",
    "\n",
    "seed = 1\n",
    "random.seed(seed)\n",
    "np.random.seed(seed*10 + 1234)\n",
    "torch.manual_seed(seed*100 + 4321)\n",
    "\n",
    "# Use GPU if available\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Device:\", device)\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Load experiment\n",
    "experiment = \"/data/talabot/experiments/to_annotate/SS29893_20190328_tdTomGC6fopt-fly3/SS29893_20190328_tdTomGC6fopt-fly3_001/\"\n",
    "# experiment = \"/mnt/NAS/CLC/Ascending_Project/SS25478/2P/20190227/SS25478-tdTomGC6fopt-fly2/SS25478-tdTomGC6fopt-fly2-002/2Pimg/\"\n",
    "ref_num = 1\n",
    "\n",
    "rgb_stack = imread_to_float(os.path.join(experiment, \"RGB.tif\"))\n",
    "if os.path.isfile(os.path.join(experiment, \"seg_ROI.tif\")):\n",
    "    seg_stack = imread_to_float(os.path.join(experiment, \"seg_ROI.tif\"))\n",
    "else:\n",
    "    seg_stack = None\n",
    "if os.path.isfile(os.path.join(experiment, \"weights.tif\")):\n",
    "    weights_stack = imread_to_float(os.path.join(experiment, \"weights.tif\"))\n",
    "else:\n",
    "    weights_stack = None\n",
    "\n",
    "@interact(image=(0, len(rgb_stack) - 1))\n",
    "def plot_experiment(image=0):\n",
    "    plt.figure(figsize=(12, 4))\n",
    "    plt.suptitle(experiment)\n",
    "    plt.subplot(131)\n",
    "    plt.title(\"Raw input\")\n",
    "    plt.imshow(rgb_stack[image])\n",
    "    if seg_stack is not None:\n",
    "        plt.subplot(132)\n",
    "        plt.title(\"Binary detection\")\n",
    "        plt.imshow(seg_stack[image], cmap=\"gray\")\n",
    "    if weights_stack is not None:\n",
    "        plt.subplot(133)\n",
    "        plt.title(\"Pixel weighting\")\n",
    "        plt.imshow(weights_stack[image], cmap=\"gray\")\n",
    "    plt.tight_layout(rect=[0, 0.03, 1, 0.95])\n",
    "    plt.show()\n",
    "\n",
    "# Compute registration through cross-correlation\n",
    "reg_rgb, reg_rows, reg_cols = register_stack(rgb_stack, ref_num=ref_num, return_shifts=True)\n",
    "reg_rgb = reg_rgb.clip(0, 1)\n",
    "if seg_stack is not None:\n",
    "    reg_seg = np.zeros_like(seg_stack)\n",
    "    for i in range(len(reg_seg)):\n",
    "        reg_seg[i] = shift_image(seg_stack[i], reg_rows[i], reg_cols[i])\n",
    "    reg_seg = reg_seg.clip(0, 1)\n",
    "else:\n",
    "    reg_seg = None\n",
    "\n",
    "plt.figure(figsize=(12, 4))\n",
    "plt.subplot(131)\n",
    "plt.title(\"Raw time projection\")\n",
    "plt.imshow(rgb_stack.mean(0) / rgb_stack.mean(0).max())\n",
    "plt.subplot(132)\n",
    "plt.title(\"Registered time projection\")\n",
    "plt.imshow(reg_rgb.mean(0) / reg_rgb.mean(0).max())\n",
    "plt.subplot(133)\n",
    "plt.title(\"Registered time projection (median)\")\n",
    "plt.imshow(np.median(reg_rgb, 0) / np.median(reg_rgb, 0).max())\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Detection\n",
    "Detect ROIs on the frames as a binary segmentation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A. Prediction\n",
    "Load a model and predict over the experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = \"../detection/deep_learning/models/190401_sep_synth_aug/\"\n",
    "out_model_name = \"../detection/deep_learning/models/test_axoid\"\n",
    "\n",
    "batch_size = 16\n",
    "\n",
    "# Load model\n",
    "input_channels = \"RG\" # Channels to use as input\n",
    "u_depth = 4\n",
    "out1_channels = 16\n",
    "# model = CustomUNet(in_channels=len(input_channels), u_depth=u_depth, \n",
    "#                    out1_channels=out1_channels, device=device)\n",
    "model = load_model(model_name, input_channels=input_channels, u_depth=u_depth, \n",
    "                   out1_channels=out1_channels, device=device)\n",
    "metrics = {\"dice\": get_dice_metric()}\n",
    "input_transform = lambda stack: normalize_range(pad_transform_stack(stack, u_depth))\n",
    "# Save future model\n",
    "os.makedirs(out_model_name, exist_ok=True)\n",
    "shutil.copy(\"utils_model.py\", os.path.join(out_model_name, \"utils_model_save.py\"))\n",
    "model_ft = copy.deepcopy(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "min_area = 16\n",
    "\n",
    "# Predict and display results\n",
    "start = time.time()\n",
    "predictions = predict_stack(model_ft, rgb_stack, batch_size, input_channels=input_channels,\n",
    "                            transform=input_transform)\n",
    "predictions = torch.sigmoid(predictions)\n",
    "detections = (predictions > 0.5).numpy().astype(np.bool)\n",
    "for i in range(len(detections)):\n",
    "    detections[i] = morphology.remove_small_objects(detections[i], min_area)\n",
    "print(\"Predicted experiment in %.1f s.\" % (time.time() - start))\n",
    "    \n",
    "if seg_stack is not None:\n",
    "    print(\"Dice =\", dice_coef(detections, seg_stack))\n",
    "\n",
    "@interact(image=(0, len(rgb_stack) - 1))\n",
    "def plot_experiment(image=0):\n",
    "    plt.figure(figsize=(12, 4))\n",
    "    plt.subplot(131)\n",
    "    plt.title(\"Raw input\")\n",
    "    plt.imshow(rgb_stack[image])\n",
    "    plt.subplot(132)\n",
    "    plt.title(\"Prediction\")\n",
    "    plt.imshow(predictions[image], cmap=\"gray\")\n",
    "    plt.subplot(133)\n",
    "    if seg_stack is not None:\n",
    "        plt.title(\"Overlay with ground truth\")\n",
    "        plt.imshow(overlay_preds_targets(detections[image], seg_stack[image]))\n",
    "    else:\n",
    "        plt.title(\"Binary prediction\")\n",
    "        plt.imshow(detections[image])\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "start = time.time()\n",
    "n_roi = np.zeros(len(rgb_stack), np.uint8)\n",
    "for i in range(len(detections)):\n",
    "    _, n = measure.label(detections[i], connectivity=1, return_num=True)\n",
    "    n_roi[i] = n\n",
    "print(\"Computation of #ROIs took %.1f s.\" % (time.time() - start))\n",
    "print(\"First occurences (except first frame): argmax = %d - argmin = %d\" % \\\n",
    "      (np.argmax(n_roi[1:]) + 1, np.argmin(n_roi[1:]) + 1))\n",
    "print(\"%d frames with less than %d ROIs\" % (np.sum(n_roi < stats.mode(n_roi)[0]), stats.mode(n_roi)[0]))\n",
    "\n",
    "f, (ax1, ax2) = plt.subplots(1, 2, figsize=(10,4), gridspec_kw={'width_ratios': [2, 1]})\n",
    "ax1.set_title(\"Number of detected ROIs through the experiment\")\n",
    "ax1.plot(n_roi)\n",
    "ax1.set_xlabel(\"Frame\")\n",
    "ax1.set_ylabel(\"Number of ROI\")\n",
    "ax2.set_title(\"Histogram of number of ROIs\")\n",
    "ax2.hist(n_roi, bins=np.arange(n_roi.min(), n_roi.max() + 2), align='left', edgecolor='k')\n",
    "ax2.set_xticks(np.arange(n_roi.min(), n_roi.max() + 1))\n",
    "ax2.set_xlabel(\"Count\")\n",
    "ax2.set_ylabel(\"Number of ROI\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### C. Manual annotation\n",
    "Create some manual annotations (outside this notebook), and fine tune the network with them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Select and annotated frames\n",
    "n_train = 3 # number of frames to annotated for training\n",
    "n_valid = 2 # number of frames to annotated for validation\n",
    "\n",
    "# Randomly choose frames\n",
    "indices = np.random.choice(np.arange(len(rgb_stack)), size=n_train + n_valid, replace=False)\n",
    "idx_train = indices[:n_train]\n",
    "idx_valid = indices[n_train:]\n",
    "print(\"Indices of annotated frames:\", idx_train, idx_valid, sep=\"\\n\")\n",
    "rgb_train = np.stack([rgb_stack[idx] for idx in idx_train])\n",
    "rgb_valid = np.stack([rgb_stack[idx] for idx in idx_valid])\n",
    "\n",
    "# Save current segmentations to use in annotation\n",
    "external.tifffile.imsave(\"/home/user/talabot/workdir/corrections.tif\", \n",
    "                         to_npint(np.stack([detections[i] for i in np.concatenate([idx_train, idx_valid])])),\n",
    "                         photometric=\"minisblack\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load manual annotations\n",
    "seg_annotated = external.tifffile.imread(\"/home/user/talabot/workdir/annotations.tif\") / 255\n",
    "seg_train = seg_annotated[:n_train]\n",
    "seg_valid = seg_annotated[n_train:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Manually add indices for annotation if annotation was not good enough\n",
    "new_idx = np.random.choice(np.arange(len(n_roi))[n_roi < 4], size=5, replace=False)\n",
    "new_idx_train = list(new_idx[:3])\n",
    "new_idx_valid = list(new_idx[3:])\n",
    "\n",
    "# Randomly choose frames\n",
    "print(\"Indices of new annotated frames:\", repr(new_idx), new_idx_train, new_idx_valid, sep=\"\\n\")\n",
    "new_rgb_train = np.stack([rgb_stack[idx] for idx in new_idx_train])\n",
    "new_rgb_valid = np.stack([rgb_stack[idx] for idx in new_idx_valid])\n",
    "\n",
    "# Save current segmentations to use in annotation\n",
    "external.tifffile.imsave(\"/home/user/talabot/workdir/corrections.tif\", \n",
    "                         to_npint(np.stack([detections[i] for i in new_idx_train + new_idx_valid])),\n",
    "                         photometric=\"minisblack\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load new manual annotations\n",
    "new_seg_annotated = external.tifffile.imread(\"/home/user/talabot/workdir/annotations.tif\") / 255\n",
    "new_seg_train = new_seg_annotated[:len(new_idx_train)]\n",
    "new_seg_valid = new_seg_annotated[len(new_idx_train):]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Concatenate previous and new annotations\n",
    "idx_train = np.concatenate([idx_train, new_idx_train])\n",
    "idx_valid = np.concatenate([idx_valid, new_idx_valid])\n",
    "rgb_train = np.concatenate([rgb_train, new_rgb_train])\n",
    "rgb_valid = np.concatenate([rgb_valid, new_rgb_valid])\n",
    "seg_train = np.concatenate([seg_train, new_seg_train])\n",
    "seg_valid = np.concatenate([seg_valid, new_seg_valid])\n",
    "print(\"Indices of annotated frames:\", idx_train, idx_valid, sep=\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### D. Fine tune the network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 0.0005\n",
    "contour, separation = False, True\n",
    "\n",
    "seg_train = seg_train.astype(rgb_train.dtype)\n",
    "seg_valid = seg_valid.astype(rgb_valid.dtype)\n",
    "weights_train = compute_weights(seg_train, contour=contour, separation=separation)\n",
    "weights_valid = compute_weights(seg_valid, contour=contour, separation=separation)\n",
    "\n",
    "@interact(image=(0, len(weights_train) + len(weights_valid) - 1))\n",
    "def plot_experiment(image=0):\n",
    "    if image < len(weights_train):\n",
    "        rgb = rgb_train\n",
    "        seg = seg_train\n",
    "        wgt = weights_train\n",
    "    else:\n",
    "        rgb = rgb_valid\n",
    "        seg = seg_valid\n",
    "        wgt = weights_valid\n",
    "    image %= len(weights_train)\n",
    "    plt.figure(figsize=(12, 4))\n",
    "    plt.subplot(131)\n",
    "    plt.title(\"Raw input\")\n",
    "    plt.imshow(rgb[image])\n",
    "    plt.subplot(132)\n",
    "    plt.title(\"Binary detection\")\n",
    "    plt.imshow(seg[image], cmap=\"gray\")\n",
    "    plt.subplot(133)\n",
    "    plt.title(\"Pixel weighting\")\n",
    "    plt.imshow(wgt[image], vmax=max(wgt[image].max(), 0.1))\n",
    "    plt.colorbar(fraction=0.035, pad=0.02)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "start = time.time()\n",
    "model_ft = fine_tune(model_ft, rgb_train, seg_train, weights_train, rgb_valid, seg_valid,\n",
    "                     data_aug=True, n_iter_min=0, n_iter_max=1000, patience=200,\n",
    "                     batch_size=batch_size, learning_rate=learning_rate, verbose=1)\n",
    "print(\"\\nFine tuning took %.1f s.\" % (time.time() - start))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. User correction (optional)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "indices = [10,  15,  61 ,111, 249, 293, 364, 484, 515, 588, 657, 669, 683, 710, 806]#np.where(n_roi < 2)[0]\n",
    "print(\"%r\" % indices)\n",
    "# First save current annotations, then edit them with annotator, and reload them\n",
    "old_seg = detections[indices].copy()\n",
    "external.tifffile.imsave(\"/home/user/talabot/workdir/corrections.tif\", to_npint(old_seg),\n",
    "                         photometric=\"minisblack\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load new manual corrections\n",
    "seg_corrections = external.tifffile.imread(\"/home/user/talabot/workdir/annotations.tif\") / 255\n",
    "detections[indices] = seg_corrections.astype(np.bool)\n",
    "\n",
    "@interact(idx=(0, len(indices) - 1))\n",
    "def plot_corrections(idx=0):\n",
    "    _, n_old = measure.label(old_seg[idx], connectivity=1, return_num=True)\n",
    "    _, n_corr = measure.label(seg_corrections[idx], connectivity=1, return_num=True)\n",
    "    \n",
    "    plt.figure(figsize=(12,4))\n",
    "    plt.suptitle(\"Frame %d\" % indices[idx])\n",
    "    plt.subplot(131)\n",
    "    plt.title(\"Raw input\")\n",
    "    plt.imshow(rgb_stack[indices[idx]])\n",
    "    plt.subplot(132)\n",
    "    plt.title(\"Network detection (%d ROIs)\" % n_old)\n",
    "    plt.imshow(old_seg[idx], cmap=\"gray\")\n",
    "    plt.subplot(133)\n",
    "    plt.title(\"After correction (%d ROIs)\" % n_corr)\n",
    "    plt.imshow(seg_corrections[idx], cmap=\"gray\")\n",
    "    plt.tight_layout(rect=[0, 0.03, 1, 0.95])\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Tracking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "init_idx = 1\n",
    "n_updates = 3\n",
    "\n",
    "id_cmap = matplotlib.cm.get_cmap('viridis')\n",
    "id_cmap.set_under([0,0,0])\n",
    "\n",
    "start = time.time()\n",
    "# Initialization\n",
    "model = InternalModel()\n",
    "identities = np.zeros(detections.shape, np.uint8)\n",
    "plt.figure(figsize=(12,4))\n",
    "model.initialize(rgb_stack[init_idx], measure.label(detections[init_idx], connectivity=1))\n",
    "plt.subplot(131)\n",
    "plt.title(\"Initial model\")\n",
    "plt.imshow(model.image, cmap=id_cmap, vmin=1)\n",
    "\n",
    "# Iterate n_updates times through the frames to udpate the model\n",
    "for n in range(n_updates):\n",
    "    for i in range(len(detections)):\n",
    "        identities[i] = model.match_frame(rgb_stack[i], detections[i], time_idx=i)\n",
    "        model.update(rgb_stack[i], identities[i], time_idx=i)\n",
    "    if n == 0:\n",
    "        plt.subplot(132)\n",
    "        plt.title(\"After 1 pass\")\n",
    "        plt.imshow(model.image, cmap=id_cmap, vmin=1)\n",
    "print(\"Updating model took %d s.\" % (time.time() - start))\n",
    "\n",
    "start = time.time()\n",
    "# Iterate a final time to finalize the identities (without updating the model)\n",
    "for i in range(len(detections)):\n",
    "    identities[i] = model.match_frame(rgb_stack[i], detections[i], time_idx=i)\n",
    "print(\"Identity matching took %d s.\" % (time.time() - start))\n",
    "plt.subplot(133)\n",
    "plt.title(\"After %d passes\" % n_updates)\n",
    "plt.imshow(model.image, cmap=id_cmap, vmin=1)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "if model.overlapping_axons:\n",
    "    print(\"Some axons are overlapping on the model's image!\")\n",
    "\n",
    "# Display resulting identities\n",
    "@interact(image = (0, len(identities) - 1))\n",
    "def plot_data(image=0):\n",
    "    plt.figure(figsize=(12,4))\n",
    "    plt.subplot(131)\n",
    "    plt.title(\"Raw input\")\n",
    "    plt.imshow(rgb_stack[image])\n",
    "    plt.subplot(132)\n",
    "    plt.title(\"Binary detection\")\n",
    "    plt.imshow(detections[image], cmap='gray')\n",
    "    plt.subplot(133)\n",
    "    plt.title(\"Identities\")\n",
    "    plt.imshow(identities[image], cmap=id_cmap, vmin=1, vmax=max([axon.id for axon in model.axons]))\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Error detection**  \n",
    "Detect tracking errors through some metrics/infos/etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot number of detected ROIs along time\n",
    "n_roi_id = np.zeros(len(identities))\n",
    "for i in range(len(n_roi)):\n",
    "    n_roi_id[i] = measure.label(identities[i].astype(detections.dtype), connectivity=1, return_num=True)[1]\n",
    "#     if n_roi_id[i] < 4:\n",
    "#         print(i)\n",
    "print(\"Argmax:\", np.argmax(n_roi_id), \"- argmin:\", np.argmin(n_roi_id))\n",
    "print(\"%d frames with less than %d ROIs\" % (np.sum(n_roi_id < len(model.axons)), len(model.axons)))\n",
    "\n",
    "plt.figure(figsize=(8,4))\n",
    "plt.subplot(121)\n",
    "plt.title(\"Number of detected ROIs through time\")\n",
    "plt.plot(n_roi, alpha=0.75)\n",
    "plt.plot(n_roi_id, alpha=0.75)\n",
    "plt.legend([\"pre-tracking\", \"post-tracking\"])\n",
    "plt.subplot(122)\n",
    "plt.title(\"Histogram of number of ROIs\")\n",
    "plt.hist(n_roi, bins=np.arange(n_roi.min(), n_roi.max() + 2), align='left', edgecolor='k', alpha=0.75)\n",
    "plt.hist(n_roi_id, bins=np.arange(n_roi_id.min(), n_roi_id.max() + 2), align='left', edgecolor='k', alpha=0.75)\n",
    "plt.xticks(np.arange(n_roi_id.min(), n_roi.max() + 1))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Look for frames where the row order of axons is violated\n",
    "# Model row orders <=> rules\n",
    "rules = get_rules(model.image)\n",
    "print(\"Model rules:\", rules, sep=\"\\n\")\n",
    "\n",
    "verifs = rules_violated(rules, identities)\n",
    "print(\"%d frames against the rules:\\n\" % np.sum(verifs),\n",
    "      [i for i in range(len(identities)) if verifs[i]], sep=\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute cost of identities for each frame and look for outliers\n",
    "# Compute first model's features\n",
    "ids_to_idx = dict()\n",
    "for i, axon in enumerate(model.axons):\n",
    "    ids_to_idx.update({axon.id: i})\n",
    "\n",
    "x_model = np.stack([axon.position for axon in model.axons], axis=0)\n",
    "x_model -= x_model.mean(0)\n",
    "area_model = np.array([axon.area for axon in model.axons])\n",
    "area_model = area_model / area_model.mean()\n",
    "\n",
    "# Loop over frames\n",
    "cost_mean = np.zeros(len(identities))\n",
    "cost_max = np.zeros(len(identities))\n",
    "for i in range(len(identities)):\n",
    "    regions = measure.regionprops(identities[i])\n",
    "    \n",
    "    # Compute frame features\n",
    "    x_frame = np.array([region.centroid for region in regions])\n",
    "    x_frame -= x_frame.mean(0)\n",
    "    area_frame = np.array([region.area for region in regions])\n",
    "    area_frame = area_frame / area_frame.mean()\n",
    "    \n",
    "    cost_matrix = model.match_inner_cost(x_frame, x_model, area_frame, area_model, identities.shape[1])\n",
    "    cost = cost_matrix[np.arange(len(regions)), np.array([ids_to_idx[reg.label] for reg in regions])]\n",
    "    if cost.size == 0:\n",
    "        cost_mean[i] = np.nan\n",
    "        cost_max[i] = np.nan\n",
    "    else:\n",
    "        cost_mean[i] = np.mean(cost)\n",
    "        cost_max[i] = np.max(cost)\n",
    "\n",
    "iqr_cutoff = 3\n",
    "cost_max_nanfree = cost_max[np.logical_not(np.isnan(cost_max))]\n",
    "cost_mean_nanfree = cost_mean[np.logical_not(np.isnan(cost_mean))]\n",
    "plt.figure(figsize=(10, 4))\n",
    "ax1 = plt.subplot(121)\n",
    "plt.title(\"Evolution of assignment cost\")\n",
    "plt.plot(cost_max)\n",
    "plt.plot(cost_mean)\n",
    "plt.legend([\"max\", \"average\"])\n",
    "plt.xlabel(\"Frame\")\n",
    "plt.ylabel(\"Cost\")\n",
    "plt.subplot(122, sharey=ax1)\n",
    "plt.title(\"Boxplots of assignment cost (whis={})\".format(iqr_cutoff))\n",
    "plt.boxplot([cost_max_nanfree, cost_mean_nanfree], whis=iqr_cutoff, labels=[\"max\", \"average\"])\n",
    "plt.ylabel(\"Cost\")\n",
    "plt.show()\n",
    "q25, q75 = np.percentile(cost_max_nanfree, 25), np.percentile(cost_max_nanfree, 75)\n",
    "iqr = q75 - q25\n",
    "outliers = np.where(cost_max_nanfree > (q75 + iqr * iqr_cutoff))[0]\n",
    "print(\"IQR {}: {}\".format(iqr_cutoff, outliers.size), outliers, sep=\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. User correction (optional)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "indices = [146, 556 , 757,  786,  790,  894,  939, 1057]\n",
    "print(indices)\n",
    "\n",
    "old_ids = identities[indices].copy()\n",
    "choice_pattern = re.compile(\"[0-9]+,[0-9]+\")\n",
    "\n",
    "# Plot frames and allow re-labeling\n",
    "for idx in indices:\n",
    "    new_id = identities[idx].copy()\n",
    "    labels, num_roi = measure.label(detections[idx], connectivity=1, return_num=True)\n",
    "    regions = measure.regionprops(labels)\n",
    "    \n",
    "    next = False\n",
    "    while not next:\n",
    "        clear_output()\n",
    "        plt.figure(figsize=(10,10))\n",
    "        plt.suptitle(\"Frame %d\" % idx)\n",
    "        plt.subplot(221)\n",
    "        plt.title(\"Model\")\n",
    "        plt.imshow(model.image, cmap=id_cmap, vmin=1, vmax=len(model.axons))\n",
    "        plt.subplot(222)\n",
    "        plt.title(\"Raw input\")\n",
    "        plt.imshow(rgb_stack[idx])\n",
    "        plt.subplot(223)\n",
    "        plt.title(\"Regions of detection\")\n",
    "        plt.imshow(labels, cmap=id_cmap, vmin=1)\n",
    "        plt.subplot(224)\n",
    "        plt.title(\"Current IDs\")\n",
    "        plt.imshow(new_id, cmap=id_cmap, vmin=1, vmax=len(model.axons))\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "        \n",
    "        choice = input(\"Choose region and id as 'r,id' ('n' for next): \")\n",
    "        if choice == \"n\":\n",
    "            next = True\n",
    "            time.sleep(1)\n",
    "            continue\n",
    "        elif not choice_pattern.match(choice):\n",
    "            print(\"Incorrect input, retry\")\n",
    "            time.sleep(1)\n",
    "            continue\n",
    "        reg, id = map(int, choice.split(\",\"))\n",
    "        \n",
    "        if reg not in np.arange(num_roi) + 1:\n",
    "            print(\"Wrong region %d\" % reg)\n",
    "            time.sleep(1)\n",
    "            continue\n",
    "        elif id not in [axon.id for axon in model.axons]:\n",
    "            if id == 0: # delete current assignment\n",
    "                new_id[labels == reg] = 0\n",
    "            else:\n",
    "                print(\"Wrong ID %d\" % id)\n",
    "            time.sleep(1)\n",
    "            continue\n",
    "        else:\n",
    "            new_id[new_id == id] = 0\n",
    "            new_id[labels == reg] = id\n",
    "        \n",
    "    identities[idx] = new_id.copy()\n",
    "clear_output()\n",
    "\n",
    "@interact(idx=(0, len(indices) - 1))\n",
    "def plot_corrections(idx=0):\n",
    "    _, n_old = measure.label(old_ids[idx], connectivity=1, return_num=True)\n",
    "    _, n_corr = measure.label(identities[idx], connectivity=1, return_num=True)\n",
    "    \n",
    "    plt.figure(figsize=(10,10))\n",
    "    plt.suptitle(\"Frame %d\" % indices[idx])\n",
    "    plt.subplot(221)\n",
    "    plt.title(\"Model\")\n",
    "    plt.imshow(model.image, cmap=id_cmap, vmin=1, vmax=len(model.axons))\n",
    "    plt.subplot(222)\n",
    "    plt.title(\"Raw input\")\n",
    "    plt.imshow(rgb_stack[indices[idx]])\n",
    "    plt.subplot(223)\n",
    "    plt.title(\"Old ID\")\n",
    "    plt.imshow(old_ids[idx], cmap=id_cmap, vmin=1, vmax=len(model.axons))\n",
    "    plt.subplot(224)\n",
    "    plt.title(\"New ID\")\n",
    "    plt.imshow(identities[indices[idx]], cmap=id_cmap, vmin=1, vmax=len(model.axons))\n",
    "    plt.tight_layout(rect=[0, 0.03, 1, 0.95])\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extract fluorescence traces\n",
    "Use the identities to extract the fluorescence traces of the axons through time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_frames_0 = 24 # number of frames for the R_0 and F_0 computation\n",
    "\n",
    "# If too many identities, do not compute traces (modify here to force computation)\n",
    "if identities.max() >= 15:\n",
    "    print(identities.max(), \"different neurons identified, traces are not computed.\\n\")\n",
    "    sys.exit()\n",
    "\n",
    "# Mean noise intensity in background\n",
    "bkg_r = np.mean(wrp_stack[np.logical_not(seg_stack),0])\n",
    "# bkg_g = np.mean(rgb_stack[np.logical_not(seg_stack),1])\n",
    "    \n",
    "traces = np.ones((identities.max(), len(identities), 2)) * np.nan\n",
    "dR_R = np.zeros((identities.max(), len(identities)))\n",
    "has_tdTom = np.array([True] * identities.max())\n",
    "\n",
    "start = time.time()\n",
    "for i in range(len(identities)):\n",
    "    for j in range(identities.max()):\n",
    "        # Select ROI (optional dilation)\n",
    "        roi = wrp_stack[i,...][(identities[i] == (j + 1))]\n",
    "        if roi.size > 0:\n",
    "            # Mean over non-zero values\n",
    "            for k in range(2):\n",
    "                traces[j , i, k] = np.mean(roi[roi[:,k] > 0, k])\n",
    "#             traces[j, i, :] = roi.mean(0)[:2]\n",
    "print(\"Computing traces took %.3f s.\" % (time.time() - start))\n",
    "\n",
    "for i in range(identities.max()):\n",
    "    # Check if tdTomato is present in the neuron by comparing the mean trace to bkg noise\n",
    "    if np.mean(traces[i, np.logical_not(np.isnan(traces[i,...,0])), 0]) >= 1.1 * bkg_r and i < 4:\n",
    "        R_t = traces[i,...,1] / traces[i,...,0]\n",
    "    else: # no tdTomato, compute F instead of R\n",
    "        R_t = traces[i,...,1]\n",
    "        has_tdTom[i] = False\n",
    "        print(\"Neuron {} has no tdTomato (mean < 1.1 * bkg: {:.3f} < {:.3f}). \"\n",
    "              \"Fluorescence computed as dF/F.\".format(\n",
    "            i + 1, np.mean(traces[i, np.logical_not(np.isnan(traces[i,...,0])), 0]), 1.1 * bkg_r))\n",
    "    R_0 = np.convolve(R_t, np.ones(n_frames_0) / n_frames_0, 'valid')\n",
    "    R_0 = np.min(np.where(np.isnan(R_0), np.inf, R_0)) # Does not consider np.nan\n",
    "    # If no window of n_frames_0 exists, search for smaller ones\n",
    "    for j in range(1, n_frames_0):\n",
    "        if not np.isinf(R_0):\n",
    "            break\n",
    "        R_0 = np.convolve(R_t, np.ones(n_frames_0 - j) / (n_frames_0 - j), 'valid')\n",
    "        R_0 = np.min(np.where(np.isnan(R_0), np.inf, R_0)) # Does not consider np.nan\n",
    "    dR_R[i] = (R_t - R_0) / R_0\n",
    "\n",
    "N = np.ceil(identities.max() / 4)\n",
    "plt.figure(figsize=(16, 4*N))\n",
    "plt.suptitle(\"Raw traces\", fontsize=14)\n",
    "ymax = 1.1 * np.where(np.isnan(traces) + np.isinf(traces), 0, traces).max()\n",
    "for i in range(identities.max()):\n",
    "    plt.subplot(N, 4, i+1)\n",
    "    plt.title(\"Neuron %d\" % (i+1))\n",
    "    plt.plot(traces[i,...,0], color=\"C3\")\n",
    "    plt.plot(traces[i,...,1], color=\"C2\")\n",
    "    plt.xlim(0, len(identities))\n",
    "    plt.ylim(0, ymax)\n",
    "    plt.legend([\"tdTomato\", \"GCaMP\"])\n",
    "plt.show()\n",
    "plt.figure(figsize=(16, 4*N))\n",
    "plt.suptitle(\"Processed traces\", fontsize=14)\n",
    "if (has_tdTom == True).any():\n",
    "    ymin_R = min(0, 1.1 * np.nan_to_num(dR_R[has_tdTom]).min())\n",
    "    ymax_R = 1.1 * np.where(np.isnan(dR_R[has_tdTom]) + np.isinf(dR_R[has_tdTom]), 0, dR_R[has_tdTom]).max()\n",
    "if (has_tdTom == False).any():\n",
    "    ymin_F = min(0, 1.1 * np.nan_to_num(dR_R[np.logical_not(has_tdTom)]).min())\n",
    "    ymax_F = 1.1 * np.where(np.isnan(dR_R[np.logical_not(has_tdTom)]) + np.isinf(dR_R[np.logical_not(has_tdTom)]),\n",
    "                            0, dR_R[np.logical_not(has_tdTom)]).max()\n",
    "for i in range(identities.max()):\n",
    "    plt.subplot(N, 4, i+1)\n",
    "    plt.title(\"Neuron %d - \" % (i+1) + (\"$\\Delta$R/R\" if has_tdTom[i] else \"$\\Delta$F/F\"))\n",
    "    plt.plot(dR_R[i], color=\"C0\" if has_tdTom[i] else \"C1\")\n",
    "    plt.xlim(0, len(identities))\n",
    "    plt.ylim(ymin_R if has_tdTom[i] else ymin_F, ymax_R if has_tdTom[i] else ymax_F)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "k = 3\n",
    "new_dR_R = dR_R.copy()\n",
    "for i in range(new_dR_R.shape[0]):\n",
    "    for j in range(new_dR_R.shape[1]):\n",
    "        new_dR_R[i, j] = np.nanmedian(dR_R[i, j - k//2:j + k//2 + 1])\n",
    "\n",
    "N = np.ceil(identities.max() / 4)\n",
    "plt.figure(figsize=(16, 4*N))\n",
    "plt.suptitle(\"Raw traces\", fontsize=14)\n",
    "ymax = 1.1 * np.where(np.isnan(traces) + np.isinf(traces), 0, traces).max()\n",
    "for i in range(identities.max()):\n",
    "    plt.subplot(N, 4, i+1)\n",
    "    plt.title(\"Neuron %d\" % (i+1))\n",
    "    plt.plot(traces[i,...,0], color=\"C3\")\n",
    "    plt.plot(traces[i,...,1], color=\"C2\")\n",
    "    plt.xlim(0, len(identities))\n",
    "    plt.ylim(0, ymax)\n",
    "    plt.legend([\"tdTomato\", \"GCaMP\"])\n",
    "plt.show()\n",
    "plt.figure(figsize=(16, 4*N))\n",
    "plt.suptitle(\"Processed traces\", fontsize=14)\n",
    "if (has_tdTom == True).any():\n",
    "    ymin_R = min(0, 1.1 * np.nan_to_num(new_dR_R[has_tdTom]).min())\n",
    "    ymax_R = 1.1 * np.where(np.isnan(new_dR_R[has_tdTom]) + np.isinf(new_dR_R[has_tdTom]), 0, \n",
    "                            new_dR_R[has_tdTom]).max()\n",
    "if (has_tdTom == False).any():\n",
    "    ymin_F = min(0, 1.1 * np.nan_to_num(new_dR_R[np.logical_not(has_tdTom)]).min())\n",
    "    ymax_F = 1.1 * np.where(np.isnan(new_dR_R[np.logical_not(has_tdTom)]) + np.isinf(new_dR_R[np.logical_not(has_tdTom)]),\n",
    "                            0, new_dR_R[np.logical_not(has_tdTom)]).max()\n",
    "for i in range(identities.max()):\n",
    "    plt.subplot(N, 4, i+1)\n",
    "    plt.title(\"Neuron %d - \" % (i+1) + (\"$\\Delta$R/R\" if has_tdTom[i] else \"$\\Delta$F/F\"))\n",
    "    plt.plot(new_dR_R[i], color=\"C0\" if has_tdTom[i] else \"C1\")\n",
    "    plt.xlim(0, len(identities))\n",
    "    plt.ylim(ymin_R if has_tdTom[i] else ymin_F, \n",
    "             ymax_R if has_tdTom[i] else ymax_F)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 3 * identities.max()))\n",
    "for i in range(identities.max()):\n",
    "    plt.subplot(identities.max(), 1, i+1)\n",
    "    plt.title(\"Neuron %d - \" % (i+1) + (\"$\\Delta$R/R\" if has_tdTom[i] else \"$\\Delta$F/F\"))\n",
    "    plt.plot(new_dR_R[i], color=\"C0\" if has_tdTom[i] else \"C1\")\n",
    "    plt.xlim(0, len(identities))\n",
    "    plt.ylim(ymin_R if has_tdTom[i] else ymin_F, \n",
    "             ymax_R if has_tdTom[i] else ymax_F)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
