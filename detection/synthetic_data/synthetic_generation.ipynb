{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Synthetic generation\n",
    "Notebook used to make whole stacks of synthetic data based on single step results (synthetic_tests.ipynb).  \n",
    "\n",
    "**Note:** the script `run_generation.py` is used to create the stacks. Functions are then written both here and in the script. The script should be the latest working version, whereas here should be for testing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import os, time\n",
    "import warnings\n",
    "import math\n",
    "import ipywidgets as widgets\n",
    "from ipywidgets import interact\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from skimage import io, draw, color, exposure\n",
    "from scipy.stats import multivariate_normal\n",
    "from imgaug import augmenters as iaa\n",
    "\n",
    "from utils_common.image import to_npint, gray2red\n",
    "from utils_common.processing import flood_fill\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Following are pre-computed on real data (dating of 21 Nov 2018). See stats_181121.pkl & README.md.\n",
    "_BKG_MEAN = 0.041733140976778674 # mean value of background\n",
    "_BKG_STD = 0.005 # Standard deviation of mean value of background (manually tuned)\n",
    "_ROI_MAX_1 = 0.2276730082246407 # fraction of ROI with 1 as max intensity\n",
    "_ROI_MAX_MEAN = 0.6625502112855037 # mean of ROI max (excluding 1.0)\n",
    "_ROI_MAX_STD = 0.13925117610178622 # std of ROI max (excluding 1.0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# All in one\n",
    "Function to create a synthetic image/stack from scratch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def synthetic_stack(shape, n_images, n_neurons):\n",
    "    \"\"\"\n",
    "    Return a stack of synthetic neural images.\n",
    "    \n",
    "    Args:\n",
    "        shape: tuple of int\n",
    "            Tuple (height, width) representing the shape of the images.\n",
    "        n_images: int\n",
    "            Number of images in the stack.\n",
    "        n_neurons: int\n",
    "            Number of neurons to be present on the stack.\n",
    "            \n",
    "    Returns:\n",
    "        synth_stack: ndarray of shape NxHxW\n",
    "            Stack of N synthetic images.\n",
    "        synth_seg: ndarray of shape NxHxW\n",
    "            Stack of N synthetic segmentations.\n",
    "    \"\"\" \n",
    "    # Initialization\n",
    "    ellipse_size = 1.5 # factor for the ground truth ellipse (normalized by std)\n",
    "    # Number of samples for each neuron (manually tuned)\n",
    "    n_samples = np.random.normal(loc=1000, scale=200, size=n_neurons) \n",
    "    if n_neurons == 1:\n",
    "        n_samples = [int(n_samples + 0.5)]\n",
    "    else:\n",
    "        n_samples = (n_samples + 0.5).astype(np.uint16)\n",
    "    grid_size = 8 # for the elastic deformation\n",
    "    \n",
    "    ## Create the gaussians representing the neurons\n",
    "    max_neurons = []\n",
    "    neurons = np.zeros((n_neurons,) + shape)\n",
    "    neurons_segs = np.zeros((n_neurons,) + shape, dtype=np.bool)\n",
    "    # Meshgrid for the gaussian weights\n",
    "    rows, cols = np.arange(shape[0]), np.arange(shape[1])\n",
    "    meshgrid = np.zeros(shape + (2,))\n",
    "    meshgrid[:,:,0], meshgrid[:,:,1] = np.meshgrid(cols, rows) # note the order!\n",
    "    for i in range(n_neurons):\n",
    "        # Create neuron infinitly until in image and no overlap with another\n",
    "        # TODO: change this to something that cannot loop to infinity\n",
    "        while True:\n",
    "            # Mean and covariance matrix of gaussian (manually tuned)\n",
    "            # Note that x and y axes are col and row (so, inversed!)\n",
    "            mean = np.array([np.random.randint(shape[1]), np.random.randint(shape[0])])\n",
    "            scale_x = shape[1] / 50\n",
    "            scale_y = shape[0] / 50\n",
    "            cross_corr = np.random.randint(-2, 2) * min(scale_x, scale_y)\n",
    "            cov = np.array([\n",
    "                [np.random.randint(1, 3) * scale_x, cross_corr],\n",
    "                [cross_corr, np.random.randint(10, 30) * scale_y]\n",
    "            ])\n",
    "\n",
    "            # Bounding ellipses\n",
    "            val, vec = np.linalg.eig(cov)\n",
    "            rotation = math.atan2(vec[0, np.argmax(val)], vec[1, np.argmax(val)])\n",
    "            rr, cc = draw.ellipse(mean[1], mean[0], \n",
    "                                  ellipse_size * np.sqrt(val[1]), ellipse_size * np.sqrt(val[0]),\n",
    "                                  rotation=rotation)\n",
    "            # Check if outside the image\n",
    "            if (rr < 0).any() or (rr >= shape[0]).any() or (cc < 0).any() or (cc >= shape[1]).any():\n",
    "                continue\n",
    "            # Check if overlapping with any existing neuron\n",
    "            elif (neurons_segs[:, rr, cc] == True).any():\n",
    "                continue\n",
    "            else:\n",
    "                break\n",
    "        neurons_segs[i, rr, cc] = True\n",
    "        \n",
    "        # Create gaussian weight image\n",
    "        neurons[i,:,:] = multivariate_normal.pdf(meshgrid, mean, cov)\n",
    "        neurons[i,:,:] /= neurons[i,:,:].sum()\n",
    "\n",
    "        # Sample randomly the neuron maximum \n",
    "        if np.random.rand() < _ROI_MAX_1:\n",
    "            max_neurons.append(1.0)\n",
    "        else:\n",
    "            loc = _ROI_MAX_MEAN\n",
    "            scale = _ROI_MAX_STD\n",
    "            max_neurons.append(np.clip(np.random.normal(loc=loc, scale=scale), 0, 1))\n",
    "        \n",
    "    # Reduce segmentations to one image\n",
    "    neurons_segs = neurons_segs.sum(axis=0)\n",
    "    \n",
    "    ## Warp neurons for each image to create the stack\n",
    "    # Define warping sequence\n",
    "    wrpseq = iaa.Sequential([\n",
    "        iaa.PiecewiseAffine(scale=0.025, nb_rows=grid_size, nb_cols=grid_size)\n",
    "    ])\n",
    "    wrp_segs = np.zeros((n_images,) + shape, dtype=np.bool)\n",
    "    wrp_neurons = np.zeros((n_images,) + shape, dtype=neurons.dtype)\n",
    "    for i in range(n_images):\n",
    "        # Set the warping to deterministic for warping both neurons and segmentation the same way\n",
    "        seq_det = wrpseq.to_deterministic()\n",
    "        \n",
    "        ## Warp the neurons\n",
    "        for j in range(n_neurons):\n",
    "            # Warp gaussian defining it\n",
    "            wrp_gaussian = seq_det.augment_image(neurons[j])\n",
    "            wrp_gaussian /= wrp_gaussian.sum()\n",
    "            # Sample from it\n",
    "            x = np.random.choice(shape[0] * shape[1], size=n_samples[j], p=wrp_gaussian.ravel())\n",
    "            y, x = np.unravel_index(x, shape)\n",
    "            hist = plt.hist2d(x, y, bins=[shape[1], shape[0]], range=[[0, shape[1]], [0, shape[0]]])\n",
    "            plt.close()\n",
    "            wrp_neurons[i] = np.maximum(wrp_neurons[i], hist[0].T / hist[0].max() * max_neurons[j])\n",
    "            \n",
    "        ## Warp the segmentation\n",
    "        wrp_segs[i] = seq_det.augment_image(neurons_segs)\n",
    "        # Fill the possible holes in warped segmentation\n",
    "        # It adds a border of background to avoid the case where a neuron is \n",
    "        # at the origin of the filling (this assumes that there aren't neurons EVERYWHERE\n",
    "        # on the border of the original image)\n",
    "        wrp_segs[i] = flood_fill(np.pad(wrp_segs[i], 1, 'constant'))[1:-1, 1:-1]\n",
    "    \n",
    "    ## Add noise (sampled from an exponential distribution)\n",
    "    noise_mean = np.random.normal(loc=_BKG_MEAN, scale=_BKG_STD)\n",
    "    noise = np.random.exponential(scale=noise_mean, size=(n_images,) + shape)\n",
    "    \n",
    "    synth_stack = np.maximum(wrp_neurons, noise)\n",
    "    synth_seg = wrp_segs\n",
    "    \n",
    "    ## Random gamma correction (with prior rescaling)\n",
    "    gamma = np.random.rand() * 0.6 + 0.7 # in [0.7, 1.3)\n",
    "    synth_stack = exposure.adjust_gamma(synth_stack / synth_stack.max(), gamma=gamma)\n",
    "    \n",
    "    return synth_stack, synth_seg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9e5227e1abaf4ac08842ba1b8569567b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(IntSlider(value=0, description='image', max=1), Output()), _dom_classes=('widget-interacâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "if np.random.rand() < 0.5: # square image half of the time\n",
    "    rand_size = np.random.randint(6, 10 + 1) * 32\n",
    "    shape = (rand_size, rand_size)\n",
    "else:\n",
    "    rand_h = np.random.randint(6, 10 + 1) * 32\n",
    "    rand_w = np.random.randint(rand_h/32, 10 + 1) * 32\n",
    "    shape = (rand_h, rand_w)\n",
    "n_images = 2 \n",
    "n_neurons = np.random.randint(2, 6 + 1)\n",
    "synth_stack, synth_seg = synthetic_stack(shape, n_images, n_neurons=n_neurons)\n",
    "\n",
    "@interact(image = (0, n_images - 1))\n",
    "def plot_data(image=0):\n",
    "    plt.figure(figsize=(14,5))\n",
    "    plt.subplot(121)\n",
    "    plt.imshow(synth_stack[image], vmin=0, vmax=1, cmap='gray')\n",
    "    plt.subplot(122)\n",
    "    plt.imshow(synth_seg[image], cmap='gray')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save synthetic stacks\n",
    "Save some synthetic stacks in the dataset. Keep them in a separate folder \"synthetic/\"."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "n_neurons = 2\n",
    "n_stacks = 78\n",
    "n_images = 600\n",
    "synth_dir = \"/data/talabot/pdm/dataset/synthetic/\"\n",
    "date = time.strftime(\"%y%m%d\", time.localtime())\n",
    "\n",
    "\n",
    "start = time.time()\n",
    "for i in range(n_stacks):\n",
    "    folder = os.path.join(synth_dir, \"synth_{}neur_{:03d}\".format(n_neurons, i))\n",
    "    print(\"Creating stack %d/%d\" % (i + 1, n_stacks), end=\"\")\n",
    "    print(\"  - folder:\", folder)\n",
    "\n",
    "    synth_stack, synth_seg = synthetic_stack(shape, n_images, n_neurons=n_neurons)\n",
    "\n",
    "    # Change synth_stack to red in RGB mode (to be consistent with deep learning code)\n",
    "    synth_stack = gray2red(synth_stack)\n",
    "\n",
    "    os.makedirs(folder, exist_ok=True)\n",
    "    os.makedirs(os.path.join(folder, \"rgb_frames\"), exist_ok=True)\n",
    "    os.makedirs(os.path.join(folder, \"seg_frames\"), exist_ok=True)\n",
    "\n",
    "    with warnings.catch_warnings():\n",
    "        warnings.simplefilter(\"ignore\")\n",
    "        # Save full stacks\n",
    "        io.imsave(os.path.join(folder, \"RGB.tif\"), to_npint(synth_stack))\n",
    "        io.imsave(os.path.join(folder, \"seg_ROI.tif\"), to_npint(synth_seg))\n",
    "        # Save image per image\n",
    "        for j in range(n_images):\n",
    "            io.imsave(os.path.join(folder, \"rgb_frames\", \"rgb_{:04}.png\".format(j)), to_npint(synth_stack[j]))\n",
    "            io.imsave(os.path.join(folder, \"seg_frames\", \"seg_{:04}.png\".format(j)), to_npint(synth_seg[j]))\n",
    "\n",
    "duration = time.time() - start\n",
    "print(\"\\nScript took {:02.0f}min {:02.0f}s.\".format(duration // 60, duration % 60))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
