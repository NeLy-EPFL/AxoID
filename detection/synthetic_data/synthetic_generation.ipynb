{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Synthetic generation\n",
    "Notebook used to make whole stacks of synthetic data based on single step results (synthetic_tests.ipynb).  \n",
    "\n",
    "**Note:** the script `run_generation.py` is used to create the stacks. Functions are then written both here and in the script. The script should be the latest working version, whereas here should be for testing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import os, time\n",
    "import warnings\n",
    "import math\n",
    "import ipywidgets as widgets\n",
    "from ipywidgets import interact\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from skimage import io, draw, color, exposure\n",
    "from scipy.stats import multivariate_normal\n",
    "from imgaug import augmenters as iaa\n",
    "\n",
    "from utils_common.image import to_npint, gray2red\n",
    "from utils_common.processing import flood_fill\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Following are pre-computed on real data. See stats_###.pkl & README.md.\n",
    "_BKG_MEAN_R = 0.04061809239988313 # mean value of red background (190222)\n",
    "_BKG_MEAN_G = 0.03090710807146899 # mean value of red background (190222)\n",
    "_BKG_STD = 0.005 # Standard deviation of mean value of background (empirically tuned)\n",
    "_ROI_MAX_1 = 0.2276730082246407 # fraction of red ROI with 1 as max intensity (181121)\n",
    "_ROI_MAX_MEAN = 0.6625502112855037 # mean of red ROI max (excluding 1.0) (181121)\n",
    "_ROI_MAX_STD = 0.13925117610178622 # std of red ROI max (excluding 1.0) (181121)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# All in one\n",
    "Function to create a synthetic image/stack from scratch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def synthetic_stack(shape, n_images, n_neurons):\n",
    "    \"\"\"\n",
    "    Return a stack of synthetic neural images.\n",
    "    \n",
    "    Args:\n",
    "        shape: tuple of int\n",
    "            Tuple (height, width) representing the shape of the images.\n",
    "        n_images: int\n",
    "            Number of images in the stack.\n",
    "        n_neurons: int\n",
    "            Number of neurons to be present on the stack.\n",
    "            \n",
    "    Returns:\n",
    "        synth_stack: ndarray of shape NxHxWx3\n",
    "            Stack of N synthetic images.\n",
    "        synth_seg: ndarray of shape NxHxW\n",
    "            Stack of N synthetic segmentations.\n",
    "    \"\"\" \n",
    "    # Initialization\n",
    "    ellipse_size = 1.5 # factor for the ground truth ellipse (normalized by std)\n",
    "    # Number of samples for each neuron (empirically tuned)\n",
    "    n_samples = np.random.normal(loc=1000, scale=200, size=n_neurons * 2).reshape([-1, 2])\n",
    "    n_samples = (n_samples + 0.5).astype(np.uint16)\n",
    "    grid_size = 8 # for the elastic deformation\n",
    "    \n",
    "    ## Create the gaussians representing the neurons\n",
    "    gaussians = np.zeros((n_neurons,) + shape)\n",
    "    neurons_seg = np.zeros(shape, dtype=np.bool)\n",
    "    # Meshgrid for the gaussian weights\n",
    "    rows, cols = np.arange(shape[0]), np.arange(shape[1])\n",
    "    meshgrid = np.zeros(shape + (2,))\n",
    "    meshgrid[:,:,0], meshgrid[:,:,1] = np.meshgrid(cols, rows) # note the order\n",
    "    for i in range(n_neurons):\n",
    "        # Loop until the randomly generated neuron is in the image \n",
    "        # and doesn't overlap with another (can theoretically loop to infinity)\n",
    "        while True:\n",
    "            # Mean and covariance matrix of gaussian (empirically tuned)\n",
    "            # Note that x and y axes are col and row (so, inversed!)\n",
    "            mean = np.array([np.random.randint(shape[1]), np.random.randint(shape[0])])\n",
    "            scale_x = shape[1] / 50\n",
    "            scale_y = shape[0] / 50\n",
    "            cross_corr = np.random.randint(-2, 2) * min(scale_x, scale_y)\n",
    "            cov = np.array([[np.random.randint(1, 3) * scale_x, cross_corr],\n",
    "                            [cross_corr, np.random.randint(10, 30) * scale_y]])\n",
    "\n",
    "            # Bounding ellipse\n",
    "            val, vec = np.linalg.eig(cov)\n",
    "            rotation = math.atan2(vec[0, np.argmax(val)], vec[1, np.argmax(val)])\n",
    "            rr, cc = draw.ellipse(mean[1], mean[0], \n",
    "                                  ellipse_size * np.sqrt(val[1]), \n",
    "                                  ellipse_size * np.sqrt(val[0]),\n",
    "                                  rotation=rotation)\n",
    "            # Check if outside the image\n",
    "            if (rr < 0).any() or (rr >= shape[0]).any() or (cc < 0).any() or (cc >= shape[1]).any():\n",
    "                continue\n",
    "            # Check if overlapping with any existing neuron\n",
    "            elif (neurons_seg[rr, cc] == True).any():\n",
    "                continue\n",
    "            else:\n",
    "                break\n",
    "        neurons_seg[rr, cc] = True\n",
    "        \n",
    "        # Create gaussian weight image\n",
    "        gaussians[i,:,:] = multivariate_normal.pdf(meshgrid, mean, cov)\n",
    "        gaussians[i,:,:] /= gaussians[i,:,:].sum()\n",
    "\n",
    "    # Choose which channels are present in each neurons\n",
    "    c_presence = np.array([[True, True], [True, False], [False, True]], dtype=np.bool)\n",
    "    channel_neurons = c_presence[np.random.choice(len(c_presence), size=n_neurons, p=[0.9, 0.05, 0.05]), :]\n",
    "    \n",
    "    # RED: choose max intensity of the neurons\n",
    "    red_max = np.zeros(n_neurons)  \n",
    "    for i in range(n_neurons):\n",
    "        if channel_neurons[i, 0] == False:\n",
    "            continue\n",
    "        # Sample randomly the neuron maximum \n",
    "        if np.random.rand() < _ROI_MAX_1:\n",
    "            red_max[i] = 1.0\n",
    "        else:\n",
    "            loc = _ROI_MAX_MEAN\n",
    "            scale = _ROI_MAX_STD\n",
    "            red_max[i] = np.clip(np.random.normal(loc=loc, scale=scale), 0, 1)\n",
    "    \n",
    "    # GREEN: choose dynamics through time of the neurons\n",
    "    green_dynamics = np.zeros((n_neurons, n_images))\n",
    "    kernel = np.exp(- (np.arange(25) - 12)**2 /50)\n",
    "    for i in range(n_neurons):\n",
    "        if channel_neurons[i, 1] == False:\n",
    "            continue\n",
    "        stimuli = np.zeros(n_images)\n",
    "        peaks = np.random.randint(n_images, size=n_images // 20)\n",
    "        stimuli[peaks] = 1.0\n",
    "        green_dynamics[i] = np.convolve(stimuli, kernel, mode=\"same\")[:n_images]\n",
    "        # If no red, assures a minimum of 0.4 to avoid invisible neurons\n",
    "        if channel_neurons[i,0]:\n",
    "            green_dynamics[i] = green_dynamics[i].clip(0,1)\n",
    "        else:\n",
    "            green_dynamics[i] = green_dynamics[i].clip(0.4,1)\n",
    "    \n",
    "    ## Warp neurons for each image to create the stack\n",
    "    # Define warping sequence\n",
    "    wrpseq = iaa.Sequential([\n",
    "        iaa.PiecewiseAffine(scale=0.025, nb_rows=grid_size, nb_cols=grid_size)\n",
    "    ])\n",
    "    wrp_segs = np.zeros((n_images,) + shape, dtype=np.bool)\n",
    "    wrp_neurons = np.zeros((n_images,) + shape + (3,), dtype=gaussians.dtype)\n",
    "    for i in range(n_images):\n",
    "        # Set the warping to deterministic for warping both neurons and segmentation the same way\n",
    "        seq_det = wrpseq.to_deterministic()\n",
    "        \n",
    "        # Warp the neurons, and create image by sampling\n",
    "        for j in range(n_neurons):\n",
    "            # Warp gaussian defining it\n",
    "            wrp_gaussian = seq_det.augment_image(gaussians[j])\n",
    "            wrp_gaussian /= wrp_gaussian.sum()\n",
    "            \n",
    "            for c in [0,1]:\n",
    "                if channel_neurons[j,c] == False:\n",
    "                    continue\n",
    "                # Sample from gaussians\n",
    "                x = np.random.choice(shape[0] * shape[1], size=n_samples[j,c], p=wrp_gaussian.ravel())\n",
    "                y, x = np.unravel_index(x, shape)\n",
    "                hist = plt.hist2d(x, y, bins=[shape[1], shape[0]], range=[[0, shape[1]], [0, shape[0]]])[0]\n",
    "                plt.close()\n",
    "                if c == 0:\n",
    "                    max_neuron = red_max[j]\n",
    "                elif c == 1:\n",
    "                    max_neuron = green_dynamics[j,i]\n",
    "                wrp_neurons[i,...,c] = np.maximum(wrp_neurons[i,...,c], hist.T / hist.max() * max_neuron)\n",
    "            \n",
    "        # Warp the segmentation\n",
    "        wrp_segs[i] = seq_det.augment_image(neurons_seg)\n",
    "        # Fill the possible holes in the warped segmentation\n",
    "        wrp_segs[i] = flood_fill(np.pad(wrp_segs[i], 1, 'constant'))[1:-1, 1:-1]\n",
    "    \n",
    "    ## Add noise (sampled from an exponential distribution)\n",
    "    noise_means = np.array([np.random.normal(loc=_BKG_MEAN_R, scale=_BKG_STD),\n",
    "                            np.random.normal(loc=_BKG_MEAN_G, scale=_BKG_STD)])\n",
    "    noise = np.stack([np.random.exponential(scale=noise_means[0], size=(n_images,) + shape),\n",
    "                      np.random.exponential(scale=noise_means[1], size=(n_images,) + shape),\n",
    "                      np.zeros((n_images,) + shape)], -1)\n",
    "    \n",
    "    synth_stack = np.maximum(wrp_neurons, noise)\n",
    "    for c in [0,1]:\n",
    "        synth_stack[...,c] /= synth_stack[...,c].max()\n",
    "    synth_seg = wrp_segs\n",
    "    \n",
    "    ## Random gamma correction (with prior rescaling)\n",
    "    gamma = np.random.rand() * 0.6 + 0.7 # in [0.7, 1.3)\n",
    "    synth_stack = exposure.adjust_gamma(synth_stack, gamma=gamma)\n",
    "    \n",
    "    return synth_stack, synth_seg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b67817f21a4c4742ac2fad114e215146",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(IntSlider(value=0, description='image', max=24), Output()), _dom_classes=('widget-intera…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "n_images = 25\n",
    "\n",
    "n_neurons = np.random.randint(2, 6 + 1)\n",
    "if np.random.rand() < 0.5: # square image half of the time\n",
    "    rand_size = np.random.randint(6, 10 + 1) * 32\n",
    "    shape = (rand_size, rand_size)\n",
    "else:\n",
    "    rand_h = np.random.randint(6, 10 + 1) * 32\n",
    "    rand_w = np.random.randint(rand_h/32, 10 + 1) * 32\n",
    "    shape = (rand_h, rand_w)\n",
    "    \n",
    "synth_stack, synth_seg = synthetic_stack(shape, n_images, n_neurons=n_neurons)\n",
    "\n",
    "@interact(image = (0, n_images - 1))\n",
    "def plot_data(image=0):\n",
    "    plt.figure(figsize=(14,5))\n",
    "    plt.subplot(121)\n",
    "    plt.imshow(synth_stack[image], vmin=0, vmax=1, cmap='gray')\n",
    "    plt.subplot(122)\n",
    "    plt.imshow(synth_seg[image], cmap='gray')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save synthetic stacks\n",
    "Save some synthetic stacks in the dataset. Keep them in a separate folder \"synthetic/\"."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "n_neurons = 2\n",
    "n_stacks = 78\n",
    "n_images = 600\n",
    "synth_dir = \"/data/talabot/pdm/dataset/synthetic/\"\n",
    "date = time.strftime(\"%y%m%d\", time.localtime())\n",
    "\n",
    "\n",
    "start = time.time()\n",
    "for i in range(n_stacks):\n",
    "    folder = os.path.join(synth_dir, \"synth_{}neur_{:03d}\".format(n_neurons, i))\n",
    "    print(\"Creating stack %d/%d\" % (i + 1, n_stacks), end=\"\")\n",
    "    print(\"  - folder:\", folder)\n",
    "\n",
    "    synth_stack, synth_seg = synthetic_stack(shape, n_images, n_neurons=n_neurons)\n",
    "\n",
    "    # Change synth_stack to red in RGB mode (to be consistent with deep learning code)\n",
    "    synth_stack = gray2red(synth_stack)\n",
    "\n",
    "    os.makedirs(folder, exist_ok=True)\n",
    "    os.makedirs(os.path.join(folder, \"rgb_frames\"), exist_ok=True)\n",
    "    os.makedirs(os.path.join(folder, \"seg_frames\"), exist_ok=True)\n",
    "\n",
    "    with warnings.catch_warnings():\n",
    "        warnings.simplefilter(\"ignore\")\n",
    "        # Save full stacks\n",
    "        io.imsave(os.path.join(folder, \"RGB.tif\"), to_npint(synth_stack))\n",
    "        io.imsave(os.path.join(folder, \"seg_ROI.tif\"), to_npint(synth_seg))\n",
    "        # Save image per image\n",
    "        for j in range(n_images):\n",
    "            io.imsave(os.path.join(folder, \"rgb_frames\", \"rgb_{:04}.png\".format(j)), to_npint(synth_stack[j]))\n",
    "            io.imsave(os.path.join(folder, \"seg_frames\", \"seg_{:04}.png\".format(j)), to_npint(synth_seg[j]))\n",
    "\n",
    "duration = time.time() - start\n",
    "print(\"\\nScript took {:02.0f}min {:02.0f}s.\".format(duration // 60, duration % 60))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
