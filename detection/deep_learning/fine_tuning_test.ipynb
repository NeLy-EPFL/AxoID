{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fine tuning test\n",
    "Test the possibility to manually annotated a few frames of the experiment, then fine tune the network on them to predict the rest of the frames.  \n",
    "This is kind of overfitting part of the test set to perform well on the rest, or domain adaptation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device: cuda:0\n",
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import os, sys, time, shutil, copy, time\n",
    "import random\n",
    "import ipywidgets as widgets\n",
    "from ipywidgets import interact\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "from skimage import io, external, measure, morphology\n",
    "from scipy import ndimage as ndi\n",
    "import cv2\n",
    "import imgaug.augmenters as iaa\n",
    "\n",
    "import torch\n",
    "\n",
    "from utils_common.image import imread_to_float, to_npint, overlay_preds_targets\n",
    "from utils_common.metrics import dice_coef\n",
    "from utils_data import normalize_range, get_all_dataloaders, pad_transform, pad_transform_stack, compute_weights\n",
    "from utils_finetuning import fine_tune, ROIAnnotator_mpl\n",
    "from utils_loss import get_BCEWithLogits_loss\n",
    "from utils_metric import get_dice_metric\n",
    "from utils_model import CustomUNet, load_model\n",
    "from utils_test import predict, predict_stack, evaluate, evaluate_stack\n",
    "\n",
    "seed = 1\n",
    "random.seed(seed)\n",
    "np.random.seed(seed*10 + 1234)\n",
    "torch.manual_seed(seed*100 + 4321)\n",
    "\n",
    "# Use GPU if available\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Device:\", device)\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 16\n",
    "learning_rate = 0.0005\n",
    "\n",
    "# Choose wether or not use synth, aug, and weights for fine tuning\n",
    "synth_data = False\n",
    "synth_ratio = None # ratio of synthetic data vs. real data\n",
    "only_synth = False # If True, will use only the synthetic data (and all of it, at the opposite of ratio=1)\n",
    "data_aug = False # If True, will use data augmentation (see below for augmentation sequence)\n",
    "use_weights = True # if False use class weights, if True use pixelwise weights (if existing)\n",
    "\n",
    "input_channels = \"RG\" # Channel to use as input\n",
    "u_depth = 4\n",
    "out1_channels = 16\n",
    "\n",
    "out_model_name = \"models/test_ft\"\n",
    "model_name = \"models/190401_sep_synth_aug/\"\n",
    "data_dir = \"/data/talabot/pdm/dataset_cv-annotated/\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare training\n",
    "Make dataloaders and so on to prepare fine tuning training"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# Create random augment sequence for data augmentation if applicable\n",
    "if data_aug:\n",
    "    seq = iaa.GammaContrast((0.7, 1.3)) # Gamma correction\n",
    "    aug_fn = seq.augment_image\n",
    "else:\n",
    "    aug_fn = lambda x: x # identity function\n",
    "\n",
    "# Create dataloaders\n",
    "dataloaders = get_all_dataloaders(\n",
    "    data_dir,\n",
    "    batch_size, \n",
    "    input_channels = input_channels,\n",
    "    test_dataloader = True,\n",
    "    use_weights = use_weights,\n",
    "    synthetic_data = synth_data, synthetic_ratio = synth_ratio, synthetic_only = only_synth,\n",
    "    train_transform = lambda img: normalize_range(pad_transform(aug_fn(img), u_depth)),\n",
    "    train_target_transform = lambda img: pad_transform(img, u_depth),\n",
    "    eval_transform = lambda img: normalize_range(pad_transform(img, u_depth)), \n",
    "    eval_target_transform = lambda img: pad_transform(img, u_depth)\n",
    ")\n",
    "# \"Deactivate\" the collate_fn of the train dataloader\n",
    "collate_fn = dataloaders[\"train\"].collate_fn\n",
    "dataloaders[\"train\"].collate_fn = lambda batch: batch\n",
    "\n",
    "# Compute class weights (as pixel imbalance)\n",
    "pos_count = 0\n",
    "neg_count = 0\n",
    "for filename in dataloaders[\"train\"].dataset.y_filenames:\n",
    "    y = io.imread(filename)\n",
    "    pos_count += (y == 255).sum()\n",
    "    neg_count += (y == 0).sum()\n",
    "pos_weight = torch.tensor((neg_count + pos_count) / (2 * pos_count)).to(device)\n",
    "neg_weight = torch.tensor((neg_count + pos_count) / (2 * neg_count)).to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'models/test_ft/utils_model_save.py'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# model = CustomUNet(in_channels=len(input_channels), u_depth=u_depth, \n",
    "#                    out1_channels=out1_channels, device=device)\n",
    "model = load_model(model_name, input_channels=input_channels, u_depth=u_depth, \n",
    "                   out1_channels=out1_channels, device=device)\n",
    "\n",
    "# loss_fn = get_BCEWithLogits_loss(pos_weight=pos_weight, neg_weight=neg_weight)\n",
    "metrics = {\"dice\": get_dice_metric()}\n",
    "\n",
    "# Save future model\n",
    "os.makedirs(out_model_name, exist_ok=True)\n",
    "shutil.copy(\"utils_model.py\", os.path.join(out_model_name, \"utils_model_save.py\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load experiments and annotated frames\n",
    "Load an experiment, predict once the detections, and create annotations for a few frames."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted experiment in 1.9 s.\n",
      "Dice = 0.9244515366189591\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ff25025f3df5423c895bf17b541e5fe8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(IntSlider(value=0, description='image', max=1066), Output()), _dom_classes=('widget-inteâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "experiment = \"/data/talabot/experiments/annotated/SS28596_20190228_tdTomGC6fopt-fly2/SS28596_20190228_tdTomGC6fopt-fly2_001/\"\n",
    "# Load experiment and segmentation & weights if available\n",
    "rgb_stack = imread_to_float(os.path.join(experiment, \"RGB.tif\"))\n",
    "if os.path.isfile(os.path.join(experiment, \"seg_ROI.tif\")):\n",
    "    seg_stack = imread_to_float(os.path.join(experiment, \"seg_ROI.tif\"))\n",
    "else:\n",
    "    seg_stack = None\n",
    "if use_weights and os.path.isfile(os.path.join(experiment, \"weights.tif\")):\n",
    "    weights_stack = imread_to_float(os.path.join(experiment, \"weights.tif\"))\n",
    "else:\n",
    "    weights_stack = None\n",
    "\n",
    "# Predict using loaded model\n",
    "start = time.time()\n",
    "predictions = predict_stack(model, rgb_stack, batch_size, input_channels=input_channels,\n",
    "                            transform=lambda stack: normalize_range(pad_transform_stack(stack, u_depth)))\n",
    "predictions = torch.sigmoid(predictions)\n",
    "print(\"Predicted experiment in %.1f s.\" % (time.time() - start))\n",
    "\n",
    "if seg_stack is not None:\n",
    "    print(\"Dice =\", dice_coef((predictions > 0.5).numpy(), seg_stack))\n",
    "\n",
    "@interact(image=(0, len(rgb_stack) - 1))\n",
    "def plot_experiment(image=0):\n",
    "    plt.figure(figsize=(12, 8))\n",
    "    plt.subplot(231)\n",
    "    plt.title(\"Raw input\")\n",
    "    plt.imshow(rgb_stack[image])\n",
    "    if seg_stack is not None:\n",
    "        plt.subplot(232)\n",
    "        plt.title(\"Binary detection\")\n",
    "        plt.imshow(seg_stack[image], cmap=\"gray\")\n",
    "    if weights_stack is not None:\n",
    "        plt.subplot(233)\n",
    "        plt.title(\"Pixel weighting\")\n",
    "        plt.imshow(weights_stack[image], cmap=\"gray\")\n",
    "    plt.subplot(235)\n",
    "    plt.title(\"Prediction\")\n",
    "    plt.imshow(predictions[image], cmap=\"gray\")\n",
    "    if seg_stack is not None:\n",
    "        plt.subplot(236)\n",
    "        plt.title(\"Overlay with ground truth\")\n",
    "        plt.imshow(overlay_preds_targets((predictions[image] > 0.5).numpy(), seg_stack[image]))\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Manual annotations\n",
    "Use the ground truth as annotations to test how many frames are needed, and how to fine tune."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Indices of annotated frames:\n",
      "[ 701 1024  835]\n",
      "[1056]\n"
     ]
    }
   ],
   "source": [
    "# Select and annotated frames\n",
    "n_train = 3 # number of frames to annotated for training\n",
    "n_valid = 1 # number of frames to annotated for validation\n",
    "\n",
    "# Randomly choose frames\n",
    "indices = np.random.choice(np.arange(len(rgb_stack)), size=n_train + n_valid, replace=False)\n",
    "indices_train = indices[:n_train]\n",
    "indices_valid = indices[n_train:]\n",
    "print(\"Indices of annotated frames:\", indices_train, indices_valid, sep=\"\\n\")\n",
    "rgb_train = np.stack([rgb_stack[idx] for idx in indices_train])\n",
    "rgb_valid = np.stack([rgb_stack[idx] for idx in indices_valid])\n",
    "seg_train = np.stack([seg_stack[idx] for idx in indices_train])\n",
    "seg_valid = np.stack([seg_stack[idx] for idx in indices_valid])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "OR Make manual annotations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Indices of annotated frames:\n",
      "[254 759 962]\n",
      "[253]\n"
     ]
    }
   ],
   "source": [
    "# Select and annotated frames\n",
    "n_train = 3 # number of frames to annotated for training\n",
    "n_valid = 1 # number of frames to annotated for validation\n",
    "\n",
    "# Randomly choose frames\n",
    "indices = np.random.choice(np.arange(len(rgb_stack)), size=n_train + n_valid, replace=False)\n",
    "indices_train = indices[:n_train]\n",
    "indices_valid = indices[n_train:]\n",
    "print(\"Indices of annotated frames:\", indices_train, indices_valid, sep=\"\\n\")\n",
    "rgb_train = np.stack([rgb_stack[idx] for idx in indices_train])\n",
    "rgb_valid = np.stack([rgb_stack[idx] for idx in indices_valid])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "seg_annotated = external.tifffile.imread(\"/home/user/talabot/workdir/annotations.tif\") / 255\n",
    "seg_train = seg_annotated[:n_train]\n",
    "seg_valid = seg_annotated[n_train:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Add other manual annotations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Indices of new annotated frames:\n",
      "[171]\n",
      "[330]\n"
     ]
    }
   ],
   "source": [
    "# Manually add indices for annotation if annotation was not good enough\n",
    "new_idx_train = [171]\n",
    "new_idx_valid = [330]\n",
    "\n",
    "# Randomly choose frames\n",
    "print(\"Indices of new annotated frames:\", new_idx_train, new_idx_valid, sep=\"\\n\")\n",
    "new_rgb_train = np.stack([rgb_stack[idx] for idx in new_idx_train])\n",
    "new_rgb_valid = np.stack([rgb_stack[idx] for idx in new_idx_valid])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_seg_annotated = external.tifffile.imread(\"/home/user/talabot/workdir/annotations.tif\") / 255\n",
    "new_seg_train = new_seg_annotated[:len(new_idx_train)]\n",
    "new_seg_valid = new_seg_annotated[len(new_idx_train):]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Add predictions as annotations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_idx_train = []\n",
    "new_idx_valid = []\n",
    "\n",
    "new_rgb_train = np.stack([rgb_stack[idx] for idx in new_idx_train])\n",
    "new_rgb_valid = np.stack([rgb_stack[idx] for idx in new_idx_valid])\n",
    "new_seg_train = np.stack([predictions_ft[idx].numpy() > 0.5 for idx in new_idx_train])\n",
    "new_seg_valid = np.stack([predictions_ft[idx].numpy() > 0.5 for idx in new_idx_valid])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Add new annotations for training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "rgb_train = np.concatenate([rgb_train, new_rgb_train])\n",
    "rgb_valid = np.concatenate([rgb_valid, new_rgb_valid])\n",
    "seg_train = np.concatenate([seg_train, new_seg_train])\n",
    "seg_valid = np.concatenate([seg_valid, new_seg_valid])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5513ed07b6ac4f8da6f6acd5e01b4928",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(IntSlider(value=0, description='image', max=3), Output()), _dom_classes=('widget-interacâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "seg_train = seg_train.astype(rgb_train.dtype)\n",
    "seg_valid = seg_valid.astype(rgb_valid.dtype)\n",
    "weights_train = compute_weights(seg_train, contour=False, separation=True)\n",
    "weights_valid = compute_weights(seg_valid, contour=False, separation=True)\n",
    "\n",
    "@interact(image=(0, len(weights_train) + len(weights_valid) - 1))\n",
    "def plot_experiment(image=0):\n",
    "    if image < len(weights_train):\n",
    "        rgb = rgb_train\n",
    "        seg = seg_train\n",
    "        wgt = weights_train\n",
    "    else:\n",
    "        rgb = rgb_valid\n",
    "        seg = seg_valid\n",
    "        wgt = weights_valid\n",
    "    image %= len(weights_train)\n",
    "    plt.figure(figsize=(10, 10))\n",
    "    plt.subplot(221)\n",
    "    plt.title(\"Raw input\")\n",
    "    plt.imshow(rgb[image])\n",
    "    plt.subplot(222)\n",
    "    plt.title(\"Binary detection\")\n",
    "    plt.imshow(seg[image], cmap=\"gray\")\n",
    "    plt.subplot(223)\n",
    "    plt.title(\"Pixel weighting\")\n",
    "    plt.imshow(wgt[image], vmax=max(wgt[image].max(), 0.1))\n",
    "    plt.colorbar(fraction=0.035, pad=0.02)\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fine tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial val_dice = 0.859619\n",
      "Iteration (max 1000): \n",
      "50: dice = 0.786288 - val_dice = 0.783133\n",
      "100: dice = 0.844215 - val_dice = 0.832000\n",
      "150: dice = 0.864947 - val_dice = 0.853377\n",
      "200: dice = 0.856151 - val_dice = 0.843648\n",
      "250: dice = 0.861842 - val_dice = 0.851064\n",
      "300: dice = 0.901811 - val_dice = 0.859038\n",
      "350: dice = 0.882349 - val_dice = 0.859038\n",
      "400: dice = 0.921157 - val_dice = 0.879865\n",
      "450: dice = 0.885019 - val_dice = 0.860927\n",
      "500: dice = 0.898484 - val_dice = 0.871022\n",
      "550: dice = 0.907299 - val_dice = 0.874576\n",
      "600: dice = 0.937127 - val_dice = 0.883562\n",
      "650: dice = 0.925254 - val_dice = 0.876481\n",
      "700: dice = 0.936181 - val_dice = 0.884354\n",
      "200 iterations without validation improvements. Fine tuning is interrupted at iteration 706.\n",
      "Best model fine tuned in iteration 506.\n",
      "\n",
      "Fine tuning took 18.7 s.\n"
     ]
    }
   ],
   "source": [
    "seg_train = seg_train.astype(rgb_train.dtype)\n",
    "seg_valid = seg_valid.astype(rgb_valid.dtype)\n",
    "if use_weights:\n",
    "    weights_train = compute_weights(seg_train, contour=False, separation=False)\n",
    "    weights_valid = compute_weights(seg_valid, contour=False, separation=False)\n",
    "else:\n",
    "    weights_train = None\n",
    "    weights_valid = None\n",
    "\n",
    "start = time.time()\n",
    "model_ft = fine_tune(model, rgb_train, seg_train, weights_train, rgb_valid, seg_valid, \n",
    "                     data_aug=True, n_iter_max=1000, patience=200, batch_size=16, learning_rate = 0.0005,\n",
    "                     verbose=1)\n",
    "print(\"\\nFine tuning took %.1f s.\" % (time.time() - start))\n",
    "last_model_ft = copy.deepcopy(model_ft)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted experiment in 2.0 s.\n",
      "Dice    = 0.9244515366189591\n",
      "Dice_ft = 0.9013191546714102\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eb9762dfbc2b42f7b96ca07b452dd93d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(IntSlider(value=0, description='image', max=1066), Output()), _dom_classes=('widget-inteâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Predict again, and compare results\n",
    "start = time.time()\n",
    "predictions_ft = predict_stack(model_ft, rgb_stack, batch_size, input_channels=input_channels,\n",
    "                               transform=lambda stack: normalize_range(pad_transform_stack(stack, u_depth)))\n",
    "predictions_ft = torch.sigmoid(predictions_ft)\n",
    "print(\"Predicted experiment in %.1f s.\" % (time.time() - start))\n",
    "\n",
    "if seg_stack is not None:\n",
    "    print(\"Dice    =\", dice_coef((predictions > 0.5).numpy(), seg_stack))\n",
    "    print(\"Dice_ft =\", dice_coef((predictions_ft > 0.5).numpy(), seg_stack))\n",
    "\n",
    "@interact(image=(0, len(rgb_stack) - 1))\n",
    "def plot_experiment(image=0):\n",
    "    plt.figure(figsize=(12, 8))\n",
    "    plt.subplot(231)\n",
    "    plt.title(\"Raw input\")\n",
    "    plt.imshow(rgb_stack[image])\n",
    "    if seg_stack is not None:     \n",
    "        plt.subplot(234)\n",
    "        plt.title(\"Binary detection\")\n",
    "        plt.imshow(seg_stack[image], cmap=\"gray\")\n",
    "    plt.subplot(232)\n",
    "    plt.title(\"Prediction\")\n",
    "    plt.imshow(predictions[image], cmap=\"gray\")\n",
    "    if seg_stack is not None:\n",
    "        plt.subplot(233)\n",
    "        plt.title(\"Overlay with ground truth\")\n",
    "        plt.imshow(overlay_preds_targets((predictions[image] > 0.5).numpy(), seg_stack[image]))\n",
    "    plt.subplot(235)\n",
    "    plt.title(\"Fine tuned prediction\")\n",
    "    plt.imshow(predictions_ft[image], cmap=\"gray\")\n",
    "    if seg_stack is not None:\n",
    "        plt.subplot(236)\n",
    "        plt.title(\"Overlay with ground truth\")\n",
    "        plt.imshow(overlay_preds_targets((predictions_ft[image] > 0.5).numpy(), seg_stack[image]))\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computation of #ROIs took 0.7 s.\n",
      "81 5\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "start = time.time()\n",
    "n_roi = []\n",
    "for i in range(len(rgb_stack)):\n",
    "    tmp = morphology.remove_small_objects(predictions_ft[i].numpy() > 0.5, 16)\n",
    "    _, n = measure.label(tmp, connectivity=1, return_num=True)\n",
    "    n_roi.append(n)\n",
    "print(\"Computation of #ROIs took %.1f s.\" % (time.time() - start))\n",
    "print(np.argmax(n_roi), np.argmin(n_roi))\n",
    "    \n",
    "plt.figure()\n",
    "plt.plot(n_roi)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "tosave = np.zeros_like(seg_stack)\n",
    "for i in range(len(rgb_stack)):\n",
    "    tosave[i] = morphology.remove_small_objects(predictions_ft[i].numpy() > 0.5, 16)\n",
    "\n",
    "io.imsave(\"/home/user/talabot/workdir/preds.tif\", to_npint(tosave))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test drawing for manual annotations\n",
    "Test drawing by mouse."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "%matplotlib notebook\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from skimage import io\n",
    "from utils_finetuning import ROIAnnotator_mpl\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "img = io.imread(\"/data/talabot/experiments/annotated/R70H06_20181202-tdTomGC6fopt-fl2/\"\n",
    "                \"R70H06-tdTomGC6fopt-fly2-001/rgb_frames/rgb_0000.png\")\n",
    "imgs = np.stack([img] * 2)\n",
    "\n",
    "roi_selector = ROIAnnotator_mpl(imgs)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "plt.figure()\n",
    "plt.subplot(121)\n",
    "plt.imshow(img)\n",
    "plt.subplot(122)\n",
    "plt.imshow(roi_selector.segmentation[0], cmap=\"gray\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
