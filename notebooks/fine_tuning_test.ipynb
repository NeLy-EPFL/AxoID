{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fine tuning test\n",
    "Test the possibility to manually annotated a few frames of the experiment, then fine tune the network on them to predict the rest of the frames.  \n",
    "This is kind of overfitting part of the test set to perform well on the rest, or sort of domain adaptation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device: cpu\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import os, sys, time, shutil, copy, time\n",
    "import random\n",
    "import ipywidgets as widgets\n",
    "from ipywidgets import interact\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "from skimage import io, external, measure, morphology\n",
    "from scipy import ndimage as ndi\n",
    "import cv2\n",
    "import imgaug.augmenters as iaa\n",
    "\n",
    "import torch\n",
    "\n",
    "# Add parent folder to path in order to access `axoid`\n",
    "sys.path.insert(0, os.path.abspath(os.path.join(os.getcwd(), '..')))\n",
    "from axoid.utils.image import imread_to_float, to_npint, overlay_preds_targets\n",
    "from axoid.utils.metrics import dice_coef\n",
    "from axoid.detection.deeplearning.data import normalize_range, get_all_dataloaders, pad_transform, \\\n",
    "                                              pad_transform_stack, compute_weights\n",
    "from axoid.detection.deeplearning.finetuning import fine_tune, ROIAnnotator_mpl\n",
    "from axoid.detection.deeplearning.loss import get_BCEWithLogits_loss\n",
    "from axoid.detection.deeplearning.metric import get_dice_metric\n",
    "from axoid.detection.deeplearning.model import CustomUNet, load_model\n",
    "from axoid.detection.deeplearning.test import predict, predict_stack, evaluate, evaluate_stack\n",
    "\n",
    "seed = 1\n",
    "random.seed(seed)\n",
    "np.random.seed(seed*10 + 1234)\n",
    "torch.manual_seed(seed*100 + 4321)\n",
    "\n",
    "# Use GPU if available\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Device:\", device)\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 16\n",
    "learning_rate = 0.0005\n",
    "\n",
    "# Choose wether or not use synth, aug, and weights for fine tuning\n",
    "synth_data = False\n",
    "synth_ratio = None # ratio of synthetic data vs. real data\n",
    "only_synth = False # If True, will use only the synthetic data (and all of it, at the opposite of ratio=1)\n",
    "data_aug = False # If True, will use data augmentation (see below for augmentation sequence)\n",
    "use_weights = True # if False use class weights, if True use pixelwise weights (if existing)\n",
    "\n",
    "input_channels = \"RG\" # Channel to use as input\n",
    "u_depth = 4\n",
    "out1_channels = 16\n",
    "\n",
    "out_model_name = \"../data/models/test_ft\"\n",
    "model_name = \"../data/models/RG_synth_190311_aug/\"\n",
    "data_dir = \"/data/talabot/pdm/dataset_cv-annotated/\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare training\n",
    "Make dataloaders and so on to prepare fine tuning training"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# Create random augment sequence for data augmentation if applicable\n",
    "if data_aug:\n",
    "    seq = iaa.GammaContrast((0.7, 1.3)) # Gamma correction\n",
    "    aug_fn = seq.augment_image\n",
    "else:\n",
    "    aug_fn = lambda x: x # identity function\n",
    "\n",
    "# Create dataloaders\n",
    "dataloaders = get_all_dataloaders(\n",
    "    data_dir,\n",
    "    batch_size, \n",
    "    input_channels = input_channels,\n",
    "    test_dataloader = True,\n",
    "    use_weights = use_weights,\n",
    "    synthetic_data = synth_data, synthetic_ratio = synth_ratio, synthetic_only = only_synth,\n",
    "    train_transform = lambda img: normalize_range(pad_transform(aug_fn(img), u_depth)),\n",
    "    train_target_transform = lambda img: pad_transform(img, u_depth),\n",
    "    eval_transform = lambda img: normalize_range(pad_transform(img, u_depth)), \n",
    "    eval_target_transform = lambda img: pad_transform(img, u_depth)\n",
    ")\n",
    "# \"Deactivate\" the collate_fn of the train dataloader\n",
    "collate_fn = dataloaders[\"train\"].collate_fn\n",
    "dataloaders[\"train\"].collate_fn = lambda batch: batch\n",
    "\n",
    "# Compute class weights (as pixel imbalance)\n",
    "pos_count = 0\n",
    "neg_count = 0\n",
    "for filename in dataloaders[\"train\"].dataset.y_filenames:\n",
    "    y = io.imread(filename)\n",
    "    pos_count += (y == 255).sum()\n",
    "    neg_count += (y == 0).sum()\n",
    "pos_weight = torch.tensor((neg_count + pos_count) / (2 * pos_count)).to(device)\n",
    "neg_weight = torch.tensor((neg_count + pos_count) / (2 * neg_count)).to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'../data/models/test_ft/utils_model_save.py'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# model = CustomUNet(in_channels=len(input_channels), u_depth=u_depth, \n",
    "#                    out1_channels=out1_channels, device=device)\n",
    "model = load_model(model_name, input_channels=input_channels, u_depth=u_depth, \n",
    "                   out1_channels=out1_channels, device=device)\n",
    "\n",
    "# loss_fn = get_BCEWithLogits_loss(pos_weight=pos_weight, neg_weight=neg_weight)\n",
    "metrics = {\"dice\": get_dice_metric()}\n",
    "    \n",
    "# Save future model\n",
    "os.makedirs(out_model_name, exist_ok=True)\n",
    "shutil.copy(\"../axoid/detection/deeplearning/model.py\", os.path.join(out_model_name, \"utils_model_save.py\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load experiments and annotated frames\n",
    "Load an experiment, predict once the detections, and create annotations for a few frames."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted experiment in 2.0 s.\n",
      "Dice = 0.5302756464675655\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "26aa7913518a4a60bae34de69b35ea55",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(IntSlider(value=0, description='image', max=1066), Output()), _dom_classes=('widget-inteâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "experiment = \"/data/talabot/experiments/annotated/SS28596_20190228_tdTomGC6fopt-fly2/SS28596_20190228_tdTomGC6fopt-fly2_001/\"\n",
    "# Load experiment and segmentation & weights if available\n",
    "rgb_stack = imread_to_float(os.path.join(experiment, \"RGB.tif\"))\n",
    "if os.path.isfile(os.path.join(experiment, \"seg_ROI.tif\")):\n",
    "    seg_stack = imread_to_float(os.path.join(experiment, \"seg_ROI.tif\"))\n",
    "else:\n",
    "    seg_stack = None\n",
    "if use_weights and os.path.isfile(os.path.join(experiment, \"weights.tif\")):\n",
    "    weights_stack = imread_to_float(os.path.join(experiment, \"weights.tif\"))\n",
    "else:\n",
    "    weights_stack = None\n",
    "\n",
    "# Predict using loaded model\n",
    "start = time.time()\n",
    "predictions = predict_stack(model, rgb_stack, batch_size, input_channels=input_channels,\n",
    "                            transform=lambda stack: normalize_range(pad_transform_stack(stack, u_depth)))\n",
    "predictions = torch.sigmoid(predictions)\n",
    "print(\"Predicted experiment in %.1f s.\" % (time.time() - start))\n",
    "\n",
    "if seg_stack is not None:\n",
    "    print(\"Dice =\", dice_coef((predictions > 0.5).numpy(), seg_stack))\n",
    "\n",
    "@interact(image=(0, len(rgb_stack) - 1))\n",
    "def plot_experiment(image=0):\n",
    "    plt.figure(figsize=(12, 8))\n",
    "    plt.subplot(231)\n",
    "    plt.title(\"Raw input\")\n",
    "    plt.imshow(rgb_stack[image])\n",
    "    if seg_stack is not None:\n",
    "        plt.subplot(232)\n",
    "        plt.title(\"Binary detection\")\n",
    "        plt.imshow(seg_stack[image], cmap=\"gray\")\n",
    "    if weights_stack is not None:\n",
    "        plt.subplot(233)\n",
    "        plt.title(\"Pixel weighting\")\n",
    "        plt.imshow(weights_stack[image], cmap=\"gray\")\n",
    "    plt.subplot(235)\n",
    "    plt.title(\"Prediction\")\n",
    "    plt.imshow(predictions[image], cmap=\"gray\")\n",
    "    if seg_stack is not None:\n",
    "        plt.subplot(236)\n",
    "        plt.title(\"Overlay with ground truth\")\n",
    "        plt.imshow(overlay_preds_targets((predictions[image] > 0.5).numpy(), seg_stack[image]))\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Manual annotations\n",
    "Use the ground truth as annotations to test how many frames are needed, and how to fine tune."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Indices of annotated frames:\n",
      "[ 701 1024  835]\n",
      "[1056]\n"
     ]
    }
   ],
   "source": [
    "# Select and annotated frames\n",
    "n_train = 5 # number of frames to annotated for training\n",
    "n_valid = 2 # number of frames to annotated for validation\n",
    "\n",
    "# Randomly choose frames\n",
    "indices = np.random.choice(np.arange(len(rgb_stack)), size=n_train + n_valid, replace=False)\n",
    "indices_train = indices[:n_train]\n",
    "indices_valid = indices[n_train:]\n",
    "print(\"Indices of annotated frames:\", indices_train, indices_valid, sep=\"\\n\")\n",
    "rgb_train = np.stack([rgb_stack[idx] for idx in indices_train])\n",
    "rgb_valid = np.stack([rgb_stack[idx] for idx in indices_valid])\n",
    "seg_train = np.stack([seg_stack[idx] for idx in indices_train])\n",
    "seg_valid = np.stack([seg_stack[idx] for idx in indices_valid])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "OR Make manual annotations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Indices of annotated frames:\n",
      "[1022  761  398   86  784]\n",
      "[1016  313]\n"
     ]
    }
   ],
   "source": [
    "# Select and annotated frames\n",
    "n_train = 5 # number of frames to annotated for training\n",
    "n_valid = 2 # number of frames to annotated for validation\n",
    "\n",
    "# Randomly choose frames\n",
    "indices = np.random.choice(np.arange(len(rgb_stack)), size=n_train + n_valid, replace=False)\n",
    "indices_train = indices[:n_train]\n",
    "indices_valid = indices[n_train:]\n",
    "print(\"Indices of annotated frames:\", indices_train, indices_valid, sep=\"\\n\")\n",
    "rgb_train = np.stack([rgb_stack[idx] for idx in indices_train])\n",
    "rgb_valid = np.stack([rgb_stack[idx] for idx in indices_valid])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "seg_annotated = external.tifffile.imread(\"/home/user/talabot/workdir/annotations.tif\") / 255\n",
    "seg_train = seg_annotated[:n_train]\n",
    "seg_valid = seg_annotated[n_train:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Add other manual annotations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Indices of new annotated frames:\n",
      "[171]\n",
      "[330]\n"
     ]
    }
   ],
   "source": [
    "# Manually add indices for annotation if annotation was not good enough\n",
    "new_idx_train = [171]\n",
    "new_idx_valid = [330]\n",
    "\n",
    "# Randomly choose frames\n",
    "print(\"Indices of new annotated frames:\", new_idx_train, new_idx_valid, sep=\"\\n\")\n",
    "new_rgb_train = np.stack([rgb_stack[idx] for idx in new_idx_train])\n",
    "new_rgb_valid = np.stack([rgb_stack[idx] for idx in new_idx_valid])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_seg_annotated = external.tifffile.imread(\"/home/user/talabot/workdir/annotations.tif\") / 255\n",
    "new_seg_train = new_seg_annotated[:len(new_idx_train)]\n",
    "new_seg_valid = new_seg_annotated[len(new_idx_train):]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Add predictions as annotations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_idx_train = []\n",
    "new_idx_valid = []\n",
    "\n",
    "new_rgb_train = np.stack([rgb_stack[idx] for idx in new_idx_train])\n",
    "new_rgb_valid = np.stack([rgb_stack[idx] for idx in new_idx_valid])\n",
    "new_seg_train = np.stack([predictions_ft[idx].numpy() > 0.5 for idx in new_idx_train])\n",
    "new_seg_valid = np.stack([predictions_ft[idx].numpy() > 0.5 for idx in new_idx_valid])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Add new annotations for training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "rgb_train = np.concatenate([rgb_train, new_rgb_train])\n",
    "rgb_valid = np.concatenate([rgb_valid, new_rgb_valid])\n",
    "seg_train = np.concatenate([seg_train, new_seg_train])\n",
    "seg_valid = np.concatenate([seg_valid, new_seg_valid])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fcf936baad1f42779fba29d7e49ee831",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(IntSlider(value=0, description='image', max=6), Output()), _dom_classes=('widget-interacâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "seg_train = seg_train.astype(rgb_train.dtype)\n",
    "seg_valid = seg_valid.astype(rgb_valid.dtype)\n",
    "weights_train = compute_weights(seg_train, contour=False, separation=True)\n",
    "weights_valid = compute_weights(seg_valid, contour=False, separation=True)\n",
    "\n",
    "@interact(image=(0, len(weights_train) + len(weights_valid) - 1))\n",
    "def plot_experiment(image=0):\n",
    "    if image < len(weights_train):\n",
    "        rgb = rgb_train\n",
    "        seg = seg_train\n",
    "        wgt = weights_train\n",
    "    else:\n",
    "        rgb = rgb_valid\n",
    "        seg = seg_valid\n",
    "        wgt = weights_valid\n",
    "    image %= len(weights_train)\n",
    "    plt.figure(figsize=(10, 10))\n",
    "    plt.subplot(221)\n",
    "    plt.title(\"Raw input\")\n",
    "    plt.imshow(rgb[image])\n",
    "    plt.subplot(222)\n",
    "    plt.title(\"Binary detection\")\n",
    "    plt.imshow(seg[image], cmap=\"gray\")\n",
    "    plt.subplot(223)\n",
    "    plt.title(\"Pixel weighting\")\n",
    "    plt.imshow(wgt[image], vmax=max(wgt[image].max(), 0.1))\n",
    "    plt.colorbar(fraction=0.035, pad=0.02)\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fine tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial val_dice = 0.457371\n",
      "Iteration (max 1000): \n",
      "50: dice = 0.873926 - val_dice = 0.678358\n",
      "100: dice = 0.912191 - val_dice = 0.747840\n",
      "150: dice = 0.936504 - val_dice = 0.740917\n",
      "200: dice = 0.947090 - val_dice = 0.747915\n",
      "250: dice = 0.959125 - val_dice = 0.789908\n",
      "300: dice = 0.935963 - val_dice = 0.749924\n",
      "350: dice = 0.971255 - val_dice = 0.766125\n",
      "400: dice = 0.961337 - val_dice = 0.771930\n",
      "200 iterations without validation improvements. Fine tuning is interrupted at iteration 431.\n",
      "Best model fine tuned in iteration 231.\n",
      "\n",
      "Fine tuning took 17.2 s.\n"
     ]
    }
   ],
   "source": [
    "seg_train = seg_train.astype(rgb_train.dtype)\n",
    "seg_valid = seg_valid.astype(rgb_valid.dtype)\n",
    "if use_weights:\n",
    "    weights_train = compute_weights(seg_train, contour=False, separation=True)\n",
    "    weights_valid = compute_weights(seg_valid, contour=False, separation=True)\n",
    "else:\n",
    "    weights_train = None\n",
    "    weights_valid = None\n",
    "\n",
    "start = time.time()\n",
    "model_ft = fine_tune(model, rgb_train, seg_train, weights_train, rgb_valid, seg_valid, \n",
    "                     data_aug=True, n_iter_max=1000, patience=200, batch_size=16, learning_rate = 0.0005,\n",
    "                     verbose=1)\n",
    "print(\"\\nFine tuning took %.1f s.\" % (time.time() - start))\n",
    "last_model_ft = copy.deepcopy(model_ft)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'model_ft' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m-----------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                             Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-a9e2e369c95a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# Predict again, and compare results\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mstart\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m predictions_ft = predict_stack(model_ft, rgb_stack, batch_size, input_channels=input_channels,\n\u001b[0m\u001b[1;32m      7\u001b[0m                                transform=lambda stack: normalize_range(pad_transform_stack(stack, u_depth)))\n\u001b[1;32m      8\u001b[0m \u001b[0mpredictions_ft\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msigmoid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpredictions_ft\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'model_ft' is not defined"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Predict again, and compare results\n",
    "start = time.time()\n",
    "predictions_ft = predict_stack(model_ft, rgb_stack, batch_size, input_channels=input_channels,\n",
    "                               transform=lambda stack: normalize_range(pad_transform_stack(stack, u_depth)))\n",
    "predictions_ft = torch.sigmoid(predictions_ft)\n",
    "print(\"Predicted experiment in %.1f s.\" % (time.time() - start))\n",
    "\n",
    "if seg_stack is not None:\n",
    "    print(\"Dice    =\", dice_coef((predictions > 0.5).numpy(), seg_stack))\n",
    "    print(\"Dice_ft =\", dice_coef((predictions_ft > 0.5).numpy(), seg_stack))\n",
    "\n",
    "@interact(image=(0, len(rgb_stack) - 1))\n",
    "def plot_experiment(image=0):\n",
    "    plt.figure(figsize=(12, 8))\n",
    "    plt.subplot(231)\n",
    "    plt.title(\"Raw input\")\n",
    "    plt.imshow(rgb_stack[image])\n",
    "    if seg_stack is not None:     \n",
    "        plt.subplot(234)\n",
    "        plt.title(\"Binary detection\")\n",
    "        plt.imshow(seg_stack[image], cmap=\"gray\")\n",
    "    plt.subplot(232)\n",
    "    plt.title(\"Prediction\")\n",
    "    plt.imshow(predictions[image], cmap=\"gray\")\n",
    "    if seg_stack is not None:\n",
    "        plt.subplot(233)\n",
    "        plt.title(\"Overlay with ground truth\")\n",
    "        plt.imshow(overlay_preds_targets((predictions[image] > 0.5).numpy(), seg_stack[image]))\n",
    "    plt.subplot(235)\n",
    "    plt.title(\"Fine tuned prediction\")\n",
    "    plt.imshow(predictions_ft[image], cmap=\"gray\")\n",
    "    if seg_stack is not None:\n",
    "        plt.subplot(236)\n",
    "        plt.title(\"Overlay with ground truth\")\n",
    "        plt.imshow(overlay_preds_targets((predictions_ft[image] > 0.5).numpy(), seg_stack[image]))\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computation of #ROIs took 0.7 s.\n",
      "747 96\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "start = time.time()\n",
    "n_roi = []\n",
    "for i in range(len(rgb_stack)):\n",
    "    tmp = morphology.remove_small_objects(predictions_ft[i].numpy() > 0.5, 16)\n",
    "    _, n = measure.label(tmp, connectivity=1, return_num=True)\n",
    "    n_roi.append(n)\n",
    "print(\"Computation of #ROIs took %.1f s.\" % (time.time() - start))\n",
    "print(np.argmax(n_roi), np.argmin(n_roi))\n",
    "    \n",
    "plt.figure()\n",
    "plt.plot(n_roi)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
